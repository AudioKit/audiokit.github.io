---
title: AudioKit Examples - Keyboard
header: Keyboard Example
permalink: /examples/Keyboard/
layout: examples
last-review-date: 2015/02/01
---

<div class="cd-iphone-6-plus cd-silver cd-landscape-left hide-on-tablets-and-smaller" style="margin-left: 1em;">
  <div class="cd-body">
    <div class="cd-sound"></div>
    <div class="cd-sleep"></div>
    <div class="cd-camera"></div>
    <div class="cd-ear"></div>
    <div class="cd-home"></div>
    <div class="cd-screen">
      <video controls class="cd-fill">
        <source src="https://dl.dropboxusercontent.com/u/31568349/movies/Keyboard.m4v" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
</div>


<p>
This examples demonstrates how a simple keyboard can be created with UIButtons for keys and UISliders to control instrument properties and a global reverb effect.
</p>

<p>
There are two parts to this example: "ToneGenerator" and "EffectsProcessor". In "ToneGenerator.m", we create a note that has frequency as an independent property of a note, not of the instrument.
</p>


{% highlight objective-c %}
ToneGeneratorNote *note = [[ToneGeneratorNote alloc] init];
{% endhighlight %}

<p>
The property "toneColor" is declared below, and initialized with some defaut values. This property is controlled by one of the sliders in the user interface.
</p>

{% highlight objective-c %}
_toneColor  = [[AKInstrumentProperty alloc] initWithValue:0.5
                                                  minimum:0.1
                                                  maximum:1.0];
[self addProperty:_toneColor];
{% endhighlight %}


<p>
Below, an instance of AKFMOscillator is created, with a sine-wave table as the source. The values of carrier multiplier, modulating multiplier, and modulation index are controlled by the toneColor parameter. These parameters are then scaled to be within a desired value range.
</p>


{% highlight objective-c %}
AKFMOscillator *fmOscillator = [AKFMOscillator oscillator];
fmOscillator.baseFrequency = note.frequency;
fmOscillator.carrierMultiplier = [_toneColor scaledBy:akp(20)];
fmOscillator.modulatingMultiplier = [_toneColor scaledBy:akp(12)];
fmOscillator.modulationIndex = [_toneColor scaledBy:akp(12)];
fmOscillator.amplitude = akp(0.15);
{% endhighlight %}

<p>
Most importantly, the output is routed to a globallly accessible auxilliary port.
</p>

{% highlight objective-c %}
_auxilliaryOutput = [AKAudio globalParameter];
[self assignOutput:_auxilliaryOutput to:fmOscillator];
{% endhighlight %}


<p>
The reverb global effect is created in "EffectsProcessor.h" with a specific initialization that requires an input audio signal:
</p>

{% highlight objective-c %}
- (instancetype)initWithAudioSource:(AKAudio *)audioSource
{% endhighlight %}

So, when the fx processor is instantiated in "ViewController.m", it is given the tone generator as its input:

{% highlight objective-c %}
fx = [[EffectsProcessor alloc] initWithAudioSource:toneGenerator.auxilliaryOutput];
{% endhighlight %}

This is how you can tie instruments and processors together for global effects.
