---
title: AudioKit Examples - Keyboard
header: Keyboard Example
permalink: /examples/swift/Keyboard/
layout: examples
last-review-date: 2015/02/01
---

<div class="cd-iphone-6-plus cd-silver cd-landscape-left hide-on-tablets-and-smaller" style="margin-left: 1em;">
  <div class="cd-body">
    <div class="cd-sound"></div>
    <div class="cd-sleep"></div>
    <div class="cd-camera"></div>
    <div class="cd-ear"></div>
    <div class="cd-home"></div>
    <div class="cd-screen">
      <video controls class="cd-fill">
        <source src="https://dl.dropboxusercontent.com/u/31568349/movies/Keyboard.m4v" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
</div>

<p>
This examples demonstrates how a simple keyboard can be created with UIButtons for keys and UISliders to control instrument properties and a global reverb effect.
</p>

<p>
There are two parts to this example: "ToneGenerator" and "EffectsProcessor". In "ToneGenerator.swift", we create a note that has frequency as an independent property of a note, not of the instrument.
</p>


{% highlight ruby %}
let note = ToneGeneratorNote()
addNoteProperty(note.frequency)
{% endhighlight %}

<p>
The property "toneColor" is declared below, and initialized with some defaut values. This property is controlled by one of the sliders in the user interface.
</p>

{% highlight ruby %}
var toneColor  = AKInstrumentProperty(value: 0.5, minimum: 0.1, maximum: 1.0)
{% endhighlight %}


<p>
Below, an instance of AKFMOscillator is created, with a sine-wave table as the source. The values of carrier multiplier, modulating multiplier, and modulation index are controlled by the toneColor parameter. These parameters are then scaled to be within a desired value range.
</p>


{% highlight ruby %}
let fmOscillator = AKFMOscillator()
fmOscillator.baseFrequency = note.frequency
fmOscillator.carrierMultiplier = toneColor.scaledBy(20.ak)
fmOscillator.modulatingMultiplier = toneColor.scaledBy(12.ak)
fmOscillator.modulationIndex = toneColor.scaledBy(15.ak)
fmOscillator.amplitude = note.amplitude.scaledBy(0.15.ak)
{% endhighlight %}

<p>
Most importantly, the output is routed to a globallly accessible auxilliary port.
</p>

{% highlight ruby %}
auxilliaryOutput = AKAudio.globalParameter()
assignOutput(auxilliaryOutput, to: fmOscillator)
{% endhighlight %}


<p>
The reverb global effect is created in "EffectsProcessor.swift" with a specific initialization that requires an input audio signal:
</p>

{% highlight ruby %}
let reverb = AKReverb(
    input: audioSource,
    feedback: feedbackLevel,
    cutoffFrequency: 4000.ak
)
{% endhighlight %}

So, when the fx processor is instantiated in Conductor.swift, it is given the tone generator as its input:

{% highlight ruby %}
fx = EffectsProcessor(audioSource: toneGenerator.auxilliaryOutput)
{% endhighlight %}

This is how you can tie instruments and processors together for global effects.
